{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Uncomment these lines if needed:\n",
        "!pip install nltk requests transformers\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "import requests\n",
        "import re\n",
        "import time\n",
        "import json\n",
        "from urllib.parse import quote\n",
        "\n",
        "#########################\n",
        "# 1. Transformer Baselines\n",
        "#########################\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "def baseline_generate_t5(question, num_candidates=5):\n",
        "    \"\"\"\n",
        "    Generates candidate answers for a question using T5 (without any external knowledge).\n",
        "    \"\"\"\n",
        "    model_name = \"t5-small\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "    input_text = \"question: \" + question\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "    outputs = model.generate(\n",
        "        input_ids,\n",
        "        max_length=50,\n",
        "        num_return_sequences=num_candidates,\n",
        "        do_sample=True,\n",
        "        top_k=50\n",
        "    )\n",
        "    return [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
        "\n",
        "def baseline_generate_bart(question, num_candidates=5):\n",
        "    \"\"\"\n",
        "    Generates candidate answers for a question using BART (without knowledge integration).\n",
        "    \"\"\"\n",
        "    model_name = \"facebook/bart-base\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "    input_ids = tokenizer.encode(question, return_tensors=\"pt\")\n",
        "    outputs = model.generate(\n",
        "        input_ids,\n",
        "        max_length=50,\n",
        "        num_return_sequences=num_candidates,\n",
        "        num_beams=num_candidates,\n",
        "        do_sample=True,\n",
        "        top_k=50\n",
        "    )\n",
        "    return [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
        "\n",
        "def baseline_generate_gpt2(question, num_candidates=5):\n",
        "    \"\"\"\n",
        "    Generates candidate answers for a question using GPT-2 (without knowledge integration).\n",
        "    \"\"\"\n",
        "    model_name = \"gpt2\"\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    encoded = tokenizer(question, return_tensors=\"pt\")\n",
        "    input_ids = encoded[\"input_ids\"]\n",
        "    attention_mask = encoded[\"attention_mask\"]\n",
        "    outputs = model.generate(\n",
        "         input_ids,\n",
        "         attention_mask=attention_mask,\n",
        "         max_length=50,\n",
        "         num_return_sequences=num_candidates,\n",
        "         num_beams=num_candidates,\n",
        "         do_sample=False,\n",
        "         pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    return [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
        "\n",
        "\n",
        "#########################\n",
        "# 2. NLTK Utilities for Lemmatization, POS Tagging, and Expansion\n",
        "#########################\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def tokenize_and_lemmatize(sentence):\n",
        "    tokens = nltk.word_tokenize(sentence.lower())\n",
        "    lemmas = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    return set(lemmas)\n",
        "\n",
        "def expand_word(word):\n",
        "    expansion = set([word])\n",
        "    for syn in wn.synsets(word):\n",
        "        for lemma in syn.lemma_names():\n",
        "            expansion.add(lemma.lower().replace(\"_\", \" \"))\n",
        "        for hyper in syn.hypernyms():\n",
        "            for lemma in hyper.lemma_names():\n",
        "                expansion.add(lemma.lower().replace(\"_\", \" \"))\n",
        "    return expansion\n",
        "\n",
        "def expand_tokens(token_set):\n",
        "    expanded = set()\n",
        "    for token in token_set:\n",
        "        expanded.update(expand_word(token))\n",
        "    return expanded\n",
        "\n",
        "def determine_expected_answer_type(question):\n",
        "    \"\"\"\n",
        "    Simple heuristic: if the question contains \"do\", \"perform\", or \"act\", expect an action; else an object.\n",
        "    \"\"\"\n",
        "    tokens = nltk.word_tokenize(question.lower())\n",
        "    if any(word in tokens for word in [\"do\", \"perform\", \"act\"]):\n",
        "        return \"action\"\n",
        "    return \"object\"\n",
        "\n",
        "#########################\n",
        "# 3. Improved Candidate Generation Using ConceptNet\n",
        "#########################\n",
        "BASE_URL = \"http://api.conceptnet.io\"\n",
        "\n",
        "def get_edges_for_term(term, limit=50):\n",
        "    url = f\"{BASE_URL}{term}?offset=0&limit={limit}\"\n",
        "    try:\n",
        "        resp = requests.get(url)\n",
        "        resp.raise_for_status()\n",
        "        data = resp.json()\n",
        "        return data.get(\"edges\", [])\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Error fetching ConceptNet data for {term}: {e}\")\n",
        "        return []\n",
        "\n",
        "def text_to_conceptnet_uri(text, lang='en'):\n",
        "    text_underscored = text.strip().lower().replace(\" \", \"_\")\n",
        "    return f\"/c/{lang}/{quote(text_underscored)}\"\n",
        "\n",
        "def extract_keywords_improved(question_text, expected_type):\n",
        "    \"\"\"\n",
        "    Improved keyword extraction:\n",
        "      - For actions, extract verbs but filter out trivial ones.\n",
        "      - For objects, extract nouns.\n",
        "      - If too few, fallback to all content words.\n",
        "    \"\"\"\n",
        "    tokens = nltk.word_tokenize(question_text.lower())\n",
        "    pos_tags = nltk.pos_tag(tokens)\n",
        "    stopwords = {\"what\", \"name\", \"something\", \"you\", \"on\", \"the\", \"a\", \"an\", \"of\"}\n",
        "\n",
        "    if expected_type == \"action\":\n",
        "        trivial_verbs = {\"name\", \"do\", \"get\", \"be\", \"have\"}\n",
        "        keywords = [word for word, tag in pos_tags if tag.startswith(\"VB\") and word not in trivial_verbs]\n",
        "        if len(keywords) < 1:\n",
        "            keywords = [word for word in tokens if word not in stopwords]\n",
        "    else:\n",
        "        keywords = [word for word, tag in pos_tags if tag.startswith(\"NN\")]\n",
        "        if len(keywords) < 1:\n",
        "            keywords = [word for word in tokens if word not in stopwords]\n",
        "\n",
        "    return keywords\n",
        "\n",
        "def filter_candidates_by_pos(candidates, expected_type):\n",
        "    \"\"\"\n",
        "    For \"action\", require at least one verb; for \"object\", require at least one noun.\n",
        "    \"\"\"\n",
        "    filtered = []\n",
        "    for candidate in candidates:\n",
        "        tokens = nltk.word_tokenize(candidate)\n",
        "        pos_tags = nltk.pos_tag(tokens)\n",
        "        if expected_type == \"action\":\n",
        "            if any(tag.startswith(\"VB\") for _, tag in pos_tags):\n",
        "                filtered.append(candidate)\n",
        "        else:\n",
        "            if any(tag.startswith(\"NN\") for _, tag in pos_tags):\n",
        "                filtered.append(candidate)\n",
        "    return filtered\n",
        "\n",
        "def generate_candidates_improved(question_text, top_k=20):\n",
        "    \"\"\"\n",
        "    Candidate generation using ConceptNet, with broader relation filters and contextual cues.\n",
        "    \"\"\"\n",
        "    expected_type = determine_expected_answer_type(question_text)\n",
        "    keywords = extract_keywords_improved(question_text, expected_type)\n",
        "\n",
        "    # If too few keywords, fallback to all content words\n",
        "    if len(keywords) < 1:\n",
        "        tokens = nltk.word_tokenize(question_text.lower())\n",
        "        stopwords = {\"what\", \"name\", \"something\", \"you\", \"on\", \"the\", \"a\", \"an\", \"of\", \"do\"}\n",
        "        keywords = [word for word in tokens if word not in stopwords]\n",
        "\n",
        "    # Add contextual cues: if the question mentions \"rain\", add related words.\n",
        "    if \"rain\" in question_text.lower():\n",
        "        contextual_cues = [\"rain\", \"rainy\", \"weather\", \"wet\", \"drizzle\"]\n",
        "        keywords = list(set(keywords).union(set(contextual_cues)))\n",
        "\n",
        "    # Relaxed relation filters:\n",
        "    if expected_type == \"action\":\n",
        "        relation_set = {\n",
        "            \"/r/UsedFor\", \"/r/CapableOf\", \"/r/MotivatedBy\", \"/r/Desires\",\n",
        "            \"/r/RelatedTo\", \"/r/HasSubevent\", \"/r/HasPrerequisite\"\n",
        "        }\n",
        "    else:\n",
        "        relation_set = {\n",
        "            \"/r/IsA\", \"/r/PartOf\", \"/r/HasA\", \"/r/RelatedTo\", \"/r/AtLocation\"\n",
        "        }\n",
        "\n",
        "    candidates = set()\n",
        "    for kw in keywords:\n",
        "        uri = text_to_conceptnet_uri(kw)\n",
        "        edges = get_edges_for_term(uri, limit=top_k)\n",
        "        for e in edges:\n",
        "            rel_id = e.get(\"rel\", {}).get(\"@id\", \"\")\n",
        "            if rel_id in relation_set:\n",
        "                end_id = e.get(\"end\", {}).get(\"@id\", \"\")\n",
        "                start_id = e.get(\"start\", {}).get(\"@id\", \"\")\n",
        "                if start_id == uri and end_id.startswith(\"/c/en/\"):\n",
        "                    candidates.add(end_id)\n",
        "                elif end_id == uri and start_id.startswith(\"/c/en/\"):\n",
        "                    candidates.add(start_id)\n",
        "\n",
        "    text_candidates = set()\n",
        "    for c in candidates:\n",
        "        cleaned = c.replace(\"/c/en/\", \"\").replace(\"_\", \" \")\n",
        "        text_candidates.add(cleaned)\n",
        "\n",
        "    # Filter candidates by expected POS\n",
        "    filtered_candidates = filter_candidates_by_pos(list(text_candidates), expected_type)\n",
        "    return filtered_candidates\n",
        "\n",
        "\n",
        "#########################\n",
        "# 4. Answer Ranking\n",
        "#########################\n",
        "def score_brevity(answer):\n",
        "    tokens = answer.split()\n",
        "    return 1.0 / len(tokens) if tokens else 0.0\n",
        "\n",
        "def get_concreteness(answer):\n",
        "    # Example dictionary for demonstration\n",
        "    concreteness_dict = {\n",
        "        'apple': 5.0,\n",
        "        'cherry': 4.5,\n",
        "        'blueberry': 4.0,\n",
        "        'watermelon': 4.0,\n",
        "        'lemon': 4.0,\n",
        "        'lime': 4.0,\n",
        "        'pineapple': 4.0,\n",
        "        'peach': 4.0,\n",
        "        'raspberry': 4.0,\n",
        "        'orange': 4.0,\n",
        "        'grape': 4.0,\n",
        "        'mango': 4.0,\n",
        "        'plums': 4.0,\n",
        "    }\n",
        "    tokens = answer.lower().split()\n",
        "    scores = [concreteness_dict.get(token, 3.0) for token in tokens]\n",
        "    return sum(scores) / len(scores) if scores else 0.0\n",
        "\n",
        "def score_typicality(question, answer):\n",
        "    q_tokens = tokenize_and_lemmatize(question)\n",
        "    a_tokens = tokenize_and_lemmatize(answer)\n",
        "    q_expanded = expand_tokens(q_tokens)\n",
        "    a_expanded = expand_tokens(a_tokens)\n",
        "    if not q_expanded or not a_expanded:\n",
        "        return 0.0\n",
        "    intersection = q_expanded.intersection(a_expanded)\n",
        "    union = q_expanded.union(a_expanded)\n",
        "    return len(intersection) / len(union)\n",
        "\n",
        "def rank_candidates_by_composite(question, candidates, weights=(0.3, 0.4, 0.3)):\n",
        "    \"\"\"\n",
        "    Ranks candidate answers by a weighted sum of brevity, concreteness, and typicality.\n",
        "    \"\"\"\n",
        "    ranked = []\n",
        "    for candidate in candidates:\n",
        "        brevity = score_brevity(candidate)\n",
        "        concreteness = get_concreteness(candidate)\n",
        "        typicality = score_typicality(question, candidate)\n",
        "        composite_score = weights[0]*brevity + weights[1]*concreteness + weights[2]*typicality\n",
        "        ranked.append((candidate, composite_score, brevity, concreteness, typicality))\n",
        "    ranked.sort(key=lambda x: x[1], reverse=True)\n",
        "    return ranked\n",
        "\n",
        "\n",
        "#########################\n",
        "# 5. Enhanced Post-Processing\n",
        "#########################\n",
        "import difflib\n",
        "\n",
        "def postprocess_candidates(ranked_candidates, question, similarity_threshold=0.8):\n",
        "    \"\"\"\n",
        "    - Removes near-duplicates (redundancy removal).\n",
        "    - Performs a basic coherence check:\n",
        "      * Removes extremely short or nonsensical answers.\n",
        "    \"\"\"\n",
        "    final = []\n",
        "    existing = []  # Accepted answers for duplication check\n",
        "\n",
        "    for cand_tuple in ranked_candidates:\n",
        "        candidate, comp_score, brevity, conc, typ = cand_tuple\n",
        "\n",
        "        # Basic length check: avoid extremely short answers.\n",
        "        if len(candidate.strip()) < 2:\n",
        "            continue\n",
        "\n",
        "        # Near-duplicate check using difflib.\n",
        "        is_duplicate = False\n",
        "        for accepted in existing:\n",
        "            ratio = difflib.SequenceMatcher(None, candidate.lower(), accepted.lower()).ratio()\n",
        "            if ratio >= similarity_threshold:\n",
        "                is_duplicate = True\n",
        "                break\n",
        "        if is_duplicate:\n",
        "            continue\n",
        "\n",
        "        final.append(cand_tuple)\n",
        "        existing.append(candidate)\n",
        "\n",
        "    return final\n",
        "\n",
        "\n",
        "#########################\n",
        "# 6. Main Pipeline\n",
        "#########################\n",
        "def main():\n",
        "    sample_data = [\n",
        "        {\n",
        "            \"question\": \"Name a fruit you might put in a pie\",\n",
        "            \"answers\": [\"apple\", \"cherry\", \"blueberry\"]\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"Name something you might do at a party\",\n",
        "            \"answers\": [\"dance\", \"talk\", \"mingle\"]\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"Name something you might find in a kitchen\",\n",
        "            \"answers\": [\"knife\", \"fork\", \"spoon\"]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    for entry in sample_data:\n",
        "        question = entry[\"question\"]\n",
        "        gold_answers = entry.get(\"answers\", [])\n",
        "        print(\"\\n==============================\")\n",
        "        print(f\"Processing Question: {question}\")\n",
        "        print(\"==============================\")\n",
        "\n",
        "        # 1) Baseline Transformer Outputs\n",
        "        print(\"\\nBaseline Evaluation (without knowledge integration):\")\n",
        "        print(\"\\nT5 Generated Answers:\")\n",
        "        for ans in baseline_generate_t5(question):\n",
        "            print(\" -\", ans)\n",
        "        print(\"\\nBART Generated Answers:\")\n",
        "        for ans in baseline_generate_bart(question):\n",
        "            print(\" -\", ans)\n",
        "        print(\"\\nGPT-2 Generated Answers:\")\n",
        "        for ans in baseline_generate_gpt2(question):\n",
        "            print(\" -\", ans)\n",
        "\n",
        "        # 2) Candidate Generation using ConceptNet\n",
        "        print(\"\\nCandidate Generation Using ConceptNet:\")\n",
        "        candidates = generate_candidates_improved(question, top_k=20)\n",
        "        if not candidates:\n",
        "            print(\"No candidates found.\")\n",
        "            print(\"\\nGold Answers (for reference):\", gold_answers)\n",
        "            continue\n",
        "        print(\"Generated Candidates (raw):\")\n",
        "        print(candidates)\n",
        "\n",
        "        # 3) Ranking\n",
        "        ranked_candidates = rank_candidates_by_composite(question, candidates)\n",
        "        print(\"\\nRanked Candidates (candidate | composite | brevity | concreteness | typicality):\")\n",
        "        for cand, comp, brev, conc, typ in ranked_candidates:\n",
        "            print(f\"{cand:30s} | {comp:8.3f} | {brev:7.3f} | {conc:11.3f} | {typ:10.3f}\")\n",
        "\n",
        "        # 4) Enhanced Post-Processing\n",
        "        print(\"\\nPost-Processing for Redundancy & Coherence:\")\n",
        "        final_candidates = postprocess_candidates(ranked_candidates, question, similarity_threshold=0.8)\n",
        "        if not final_candidates:\n",
        "            print(\"All candidates removed during post-processing.\")\n",
        "        else:\n",
        "            print(\"Final Post-Processed Candidates:\")\n",
        "            for cand, comp, brev, conc, typ in final_candidates:\n",
        "                print(f\"{cand:30s} | {comp:8.3f} | {brev:7.3f} | {conc:11.3f} | {typ:10.3f}\")\n",
        "\n",
        "        print(\"\\nGold Answers (for reference):\")\n",
        "        print(gold_answers)\n",
        "\n",
        "        time.sleep(0.5)\n",
        "\n",
        "        time.sleep(0.5)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHH513dY2Y_Y",
        "outputId": "4991137e-c4e7-4c1b-c45f-761299d94048"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==============================\n",
            "Processing Question: Name a fruit you might put in a pie\n",
            "==============================\n",
            "\n",
            "Baseline Evaluation (without knowledge integration):\n",
            "\n",
            "T5 Generated Answers:\n",
            " - Identify an fruit you might put in a pie\n",
            " - don't forget your name.\n",
            " - name a fruit as a fruit you might put in a pie\n",
            " - names\n",
            " - nom\n",
            "\n",
            "BART Generated Answers:\n",
            " - Name a fruit you might put in a pie\n",
            " - Name a fruit you might put in a pie.\n",
            " - Name a fruit you might put in a pieadvertisement\n",
            " - Name a fruit you might put in a pie;\n",
            " - Name a fruit you might put in a pie (\n",
            "\n",
            "GPT-2 Generated Answers:\n",
            " - Name a fruit you might put in a pie crust.\n",
            "\n",
            "You can also make your own pie crust by using a pastry brush.\n",
            "\n",
            "You can also make your own pie crust by using a pastry brush. You can also make your own pie\n",
            " - Name a fruit you might put in a pie crust.\n",
            "\n",
            "You can also make your own pie crust by using a pastry brush.\n",
            "\n",
            "You can also make your own pie crust by using a pastry brush.\n",
            "\n",
            "You can also make your\n",
            " - Name a fruit you might put in a pie crust.\n",
            "\n",
            "You can also make your own pie crust by using a pie cutter.\n",
            "\n",
            "You can also make your own pie crust by using a pie cutter. You can also make your own pie\n",
            " - Name a fruit you might put in a pie crust.\n",
            "\n",
            "You can also make your own pie crust by using a pie crust cutter.\n",
            "\n",
            "You can also make your own pie crust by using a pie crust cutter. You can also make your\n",
            " - Name a fruit you might put in a pie crust.\n",
            "\n",
            "You can also make your own pie crust by using a pie crust cutter.\n",
            "\n",
            "You can also make your own pie crust by using a pie crust cutter.\n",
            "\n",
            "You can also\n",
            "\n",
            "Candidate Generation Using ConceptNet:\n",
            "Generated Candidates (raw):\n",
            "['peach', 'watermelon', 'mark', 'title', 'apple', 'pineapple', 'every person', 'good source of vitamins', 'market', 'dessert', 'person', 'raspberry', 'plums', 'identification', 'lemon', 'grape', 'mango', 'orange', 'better snack than candy', 'alias', 'label', 'nomenclature', 'identity', 'moniker', 'produce', 'cake', 'lime', 'tree', 'windowsill']\n",
            "\n",
            "Ranked Candidates (candidate | composite | brevity | concreteness | typicality):\n",
            "apple                          |    2.300 |   1.000 |       5.000 |      0.000\n",
            "plums                          |    1.903 |   1.000 |       4.000 |      0.011\n",
            "raspberry                      |    1.902 |   1.000 |       4.000 |      0.005\n",
            "peach                          |    1.901 |   1.000 |       4.000 |      0.005\n",
            "watermelon                     |    1.900 |   1.000 |       4.000 |      0.000\n",
            "pineapple                      |    1.900 |   1.000 |       4.000 |      0.000\n",
            "lemon                          |    1.900 |   1.000 |       4.000 |      0.000\n",
            "grape                          |    1.900 |   1.000 |       4.000 |      0.000\n",
            "mango                          |    1.900 |   1.000 |       4.000 |      0.000\n",
            "orange                         |    1.900 |   1.000 |       4.000 |      0.000\n",
            "lime                           |    1.900 |   1.000 |       4.000 |      0.000\n",
            "mark                           |    1.509 |   1.000 |       3.000 |      0.029\n",
            "market                         |    1.505 |   1.000 |       3.000 |      0.016\n",
            "label                          |    1.505 |   1.000 |       3.000 |      0.015\n",
            "produce                        |    1.503 |   1.000 |       3.000 |      0.011\n",
            "person                         |    1.503 |   1.000 |       3.000 |      0.010\n",
            "title                          |    1.503 |   1.000 |       3.000 |      0.010\n",
            "tree                           |    1.503 |   1.000 |       3.000 |      0.010\n",
            "nomenclature                   |    1.502 |   1.000 |       3.000 |      0.006\n",
            "alias                          |    1.502 |   1.000 |       3.000 |      0.006\n",
            "dessert                        |    1.500 |   1.000 |       3.000 |      0.000\n",
            "identification                 |    1.500 |   1.000 |       3.000 |      0.000\n",
            "identity                       |    1.500 |   1.000 |       3.000 |      0.000\n",
            "moniker                        |    1.500 |   1.000 |       3.000 |      0.000\n",
            "cake                           |    1.500 |   1.000 |       3.000 |      0.000\n",
            "windowsill                     |    1.500 |   1.000 |       3.000 |      0.000\n",
            "every person                   |    1.353 |   0.500 |       3.000 |      0.010\n",
            "better snack than candy        |    1.279 |   0.250 |       3.000 |      0.012\n",
            "good source of vitamins        |    1.275 |   0.250 |       3.000 |      0.000\n",
            "\n",
            "Post-Processing for Redundancy & Coherence:\n",
            "Final Post-Processed Candidates:\n",
            "apple                          |    2.300 |   1.000 |       5.000 |      0.000\n",
            "plums                          |    1.903 |   1.000 |       4.000 |      0.011\n",
            "raspberry                      |    1.902 |   1.000 |       4.000 |      0.005\n",
            "peach                          |    1.901 |   1.000 |       4.000 |      0.005\n",
            "watermelon                     |    1.900 |   1.000 |       4.000 |      0.000\n",
            "pineapple                      |    1.900 |   1.000 |       4.000 |      0.000\n",
            "lemon                          |    1.900 |   1.000 |       4.000 |      0.000\n",
            "grape                          |    1.900 |   1.000 |       4.000 |      0.000\n",
            "mango                          |    1.900 |   1.000 |       4.000 |      0.000\n",
            "orange                         |    1.900 |   1.000 |       4.000 |      0.000\n",
            "lime                           |    1.900 |   1.000 |       4.000 |      0.000\n",
            "mark                           |    1.509 |   1.000 |       3.000 |      0.029\n",
            "label                          |    1.505 |   1.000 |       3.000 |      0.015\n",
            "produce                        |    1.503 |   1.000 |       3.000 |      0.011\n",
            "person                         |    1.503 |   1.000 |       3.000 |      0.010\n",
            "title                          |    1.503 |   1.000 |       3.000 |      0.010\n",
            "tree                           |    1.503 |   1.000 |       3.000 |      0.010\n",
            "nomenclature                   |    1.502 |   1.000 |       3.000 |      0.006\n",
            "alias                          |    1.502 |   1.000 |       3.000 |      0.006\n",
            "dessert                        |    1.500 |   1.000 |       3.000 |      0.000\n",
            "identification                 |    1.500 |   1.000 |       3.000 |      0.000\n",
            "identity                       |    1.500 |   1.000 |       3.000 |      0.000\n",
            "moniker                        |    1.500 |   1.000 |       3.000 |      0.000\n",
            "cake                           |    1.500 |   1.000 |       3.000 |      0.000\n",
            "windowsill                     |    1.500 |   1.000 |       3.000 |      0.000\n",
            "every person                   |    1.353 |   0.500 |       3.000 |      0.010\n",
            "better snack than candy        |    1.279 |   0.250 |       3.000 |      0.012\n",
            "good source of vitamins        |    1.275 |   0.250 |       3.000 |      0.000\n",
            "\n",
            "Gold Answers (for reference):\n",
            "['apple', 'cherry', 'blueberry']\n",
            "\n",
            "==============================\n",
            "Processing Question: Name something you might do at a party\n",
            "==============================\n",
            "\n",
            "Baseline Evaluation (without knowledge integration):\n",
            "\n",
            "T5 Generated Answers:\n",
            " - not\n",
            " - nom or tag yourself in a party\n",
            " - name something you might make during a party\n",
            " - Tick those or make a number on your birthday page or to make any noise\n",
            " - Be the person for your birthday\n",
            "\n",
            "BART Generated Answers:\n",
            " - Name something you might do at a party\n",
            " - Name something you might do at a partyadvertisement\n",
            " - Name something you might do at a party or a party\n",
            " - Name something you might do at a partyadvertisementadvertisement\n",
            " - Name something you might do at a party or party\n",
            "\n",
            "GPT-2 Generated Answers:\n",
            " - Name something you might do at a party.\n",
            "\n",
            "If you don't know what you're doing, ask for help.\n",
            "\n",
            "If you don't know what you're doing, ask for help. If you don't know what you're doing\n",
            " - Name something you might do at a party.\n",
            "\n",
            "If you don't know what you're doing, ask for help.\n",
            "\n",
            "If you don't know what you're doing, ask for help.\n",
            "\n",
            "If you don't know what you\n",
            " - Name something you might do at a party.\n",
            "\n",
            "If you don't know what you're doing, ask for help.\n",
            "\n",
            "If you don't know what you're doing, ask for help.\n",
            "\n",
            "If you don't know how to\n",
            " - Name something you might do at a party.\n",
            "\n",
            "If you don't know what you're doing, ask for help.\n",
            "\n",
            "If you don't know what you're doing, ask for help. If you don't know what you want to\n",
            " - Name something you might do at a party.\n",
            "\n",
            "If you don't know what you're doing, ask for help.\n",
            "\n",
            "If you don't know what you're doing, ask for help. If you don't know what you want,\n",
            "\n",
            "Candidate Generation Using ConceptNet:\n",
            "Generated Candidates (raw):\n",
            "['celebrating', 'having friends over']\n",
            "\n",
            "Ranked Candidates (candidate | composite | brevity | concreteness | typicality):\n",
            "celebrating                    |    1.503 |   1.000 |       3.000 |      0.011\n",
            "having friends over            |    1.310 |   0.333 |       3.000 |      0.034\n",
            "\n",
            "Post-Processing for Redundancy & Coherence:\n",
            "Final Post-Processed Candidates:\n",
            "celebrating                    |    1.503 |   1.000 |       3.000 |      0.011\n",
            "having friends over            |    1.310 |   0.333 |       3.000 |      0.034\n",
            "\n",
            "Gold Answers (for reference):\n",
            "['dance', 'talk', 'mingle']\n",
            "\n",
            "==============================\n",
            "Processing Question: Name something you might find in a kitchen\n",
            "==============================\n",
            "\n",
            "Baseline Evaluation (without knowledge integration):\n",
            "\n",
            "T5 Generated Answers:\n",
            " - do a search\n",
            " - Describe the things you might find in a kitchen\n",
            " - the name\n",
            " - you might find in a kitchen\n",
            " - refer\n",
            "\n",
            "BART Generated Answers:\n",
            " - Name something you might find in a kitchen\n",
            " - Name something you might find in a kitchen.\n",
            " - Name something you might find in a Kitchen\n",
            " - Name something you might find in a restaurant\n",
            " - Name something you might find in a house:\n",
            "\n",
            "GPT-2 Generated Answers:\n",
            " - Name something you might find in a kitchen.\n",
            "\n",
            "If you're not sure what you're looking for, check out our list of the best kitchen gadgets.\n",
            "\n",
            "If you're not sure what you're looking for, check out our list of\n",
            " - Name something you might find in a kitchen.\n",
            "\n",
            "If you're not sure what you're looking for, check out our list of the best kitchen gadgets.\n",
            "\n",
            "If you're not sure what you're looking for, try our list of the\n",
            " - Name something you might find in a kitchen.\n",
            "\n",
            "If you're not sure what you're looking for, check out our list of the best kitchen gadgets.\n",
            "\n",
            "If you're not sure what you're looking for, check out the list of\n",
            " - Name something you might find in a kitchen.\n",
            "\n",
            "If you're not sure what you're looking for, check out our list of the best kitchen gadgets.\n",
            "\n",
            "If you're not sure what you're looking for, check out this list of\n",
            " - Name something you might find in a kitchen.\n",
            "\n",
            "If you're not sure what you're looking for, check out our list of the best kitchen gadgets.\n",
            "\n",
            "If you're not sure what you're looking for, check out our kitchen gadgets\n",
            "\n",
            "Candidate Generation Using ConceptNet:\n",
            "Generated Candidates (raw):\n",
            "['knives', 'corner cupboard', 'mark', 'food', 'sink', 'title', 'every person', 'table', 'saucepan', 'knife', 'person', 'mouse', 'plate', 'cabinets', 'identification', 'kettle', 'grape', 'alias', 'label', 'linoleum', 'nomenclature', 'pantry', 'identity', 'moniker', 'fork', 'potato', 'icebox', 'gun/v/wikt/en 1']\n",
            "\n",
            "Ranked Candidates (candidate | composite | brevity | concreteness | typicality):\n",
            "grape                          |    1.900 |   1.000 |       4.000 |      0.000\n",
            "mark                           |    1.508 |   1.000 |       3.000 |      0.028\n",
            "label                          |    1.506 |   1.000 |       3.000 |      0.020\n",
            "title                          |    1.504 |   1.000 |       3.000 |      0.014\n",
            "alias                          |    1.502 |   1.000 |       3.000 |      0.005\n",
            "person                         |    1.501 |   1.000 |       3.000 |      0.005\n",
            "table                          |    1.501 |   1.000 |       3.000 |      0.005\n",
            "plate                          |    1.501 |   1.000 |       3.000 |      0.005\n",
            "sink                           |    1.501 |   1.000 |       3.000 |      0.004\n",
            "knives                         |    1.500 |   1.000 |       3.000 |      0.000\n",
            "food                           |    1.500 |   1.000 |       3.000 |      0.000\n",
            "saucepan                       |    1.500 |   1.000 |       3.000 |      0.000\n",
            "knife                          |    1.500 |   1.000 |       3.000 |      0.000\n",
            "mouse                          |    1.500 |   1.000 |       3.000 |      0.000\n",
            "cabinets                       |    1.500 |   1.000 |       3.000 |      0.000\n",
            "identification                 |    1.500 |   1.000 |       3.000 |      0.000\n",
            "kettle                         |    1.500 |   1.000 |       3.000 |      0.000\n",
            "linoleum                       |    1.500 |   1.000 |       3.000 |      0.000\n",
            "nomenclature                   |    1.500 |   1.000 |       3.000 |      0.000\n",
            "pantry                         |    1.500 |   1.000 |       3.000 |      0.000\n",
            "identity                       |    1.500 |   1.000 |       3.000 |      0.000\n",
            "moniker                        |    1.500 |   1.000 |       3.000 |      0.000\n",
            "fork                           |    1.500 |   1.000 |       3.000 |      0.000\n",
            "potato                         |    1.500 |   1.000 |       3.000 |      0.000\n",
            "icebox                         |    1.500 |   1.000 |       3.000 |      0.000\n",
            "gun/v/wikt/en 1                |    1.352 |   0.500 |       3.000 |      0.005\n",
            "every person                   |    1.351 |   0.500 |       3.000 |      0.005\n",
            "corner cupboard                |    1.350 |   0.500 |       3.000 |      0.000\n",
            "\n",
            "Post-Processing for Redundancy & Coherence:\n",
            "Final Post-Processed Candidates:\n",
            "grape                          |    1.900 |   1.000 |       4.000 |      0.000\n",
            "mark                           |    1.508 |   1.000 |       3.000 |      0.028\n",
            "label                          |    1.506 |   1.000 |       3.000 |      0.020\n",
            "title                          |    1.504 |   1.000 |       3.000 |      0.014\n",
            "alias                          |    1.502 |   1.000 |       3.000 |      0.005\n",
            "person                         |    1.501 |   1.000 |       3.000 |      0.005\n",
            "table                          |    1.501 |   1.000 |       3.000 |      0.005\n",
            "plate                          |    1.501 |   1.000 |       3.000 |      0.005\n",
            "sink                           |    1.501 |   1.000 |       3.000 |      0.004\n",
            "knives                         |    1.500 |   1.000 |       3.000 |      0.000\n",
            "food                           |    1.500 |   1.000 |       3.000 |      0.000\n",
            "saucepan                       |    1.500 |   1.000 |       3.000 |      0.000\n",
            "knife                          |    1.500 |   1.000 |       3.000 |      0.000\n",
            "mouse                          |    1.500 |   1.000 |       3.000 |      0.000\n",
            "cabinets                       |    1.500 |   1.000 |       3.000 |      0.000\n",
            "identification                 |    1.500 |   1.000 |       3.000 |      0.000\n",
            "kettle                         |    1.500 |   1.000 |       3.000 |      0.000\n",
            "linoleum                       |    1.500 |   1.000 |       3.000 |      0.000\n",
            "nomenclature                   |    1.500 |   1.000 |       3.000 |      0.000\n",
            "pantry                         |    1.500 |   1.000 |       3.000 |      0.000\n",
            "identity                       |    1.500 |   1.000 |       3.000 |      0.000\n",
            "moniker                        |    1.500 |   1.000 |       3.000 |      0.000\n",
            "fork                           |    1.500 |   1.000 |       3.000 |      0.000\n",
            "potato                         |    1.500 |   1.000 |       3.000 |      0.000\n",
            "icebox                         |    1.500 |   1.000 |       3.000 |      0.000\n",
            "gun/v/wikt/en 1                |    1.352 |   0.500 |       3.000 |      0.005\n",
            "every person                   |    1.351 |   0.500 |       3.000 |      0.005\n",
            "corner cupboard                |    1.350 |   0.500 |       3.000 |      0.000\n",
            "\n",
            "Gold Answers (for reference):\n",
            "['knife', 'fork', 'spoon']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0tQYSB-E9Kkv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
